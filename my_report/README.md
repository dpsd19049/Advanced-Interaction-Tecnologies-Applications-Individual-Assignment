# Lesson: Advanced Interaction Technologies & Applications

### First and Last Name: Konstantinos Karyotis
### University Registration Number: dpsd19049
### GitHub Personal Profile: https://github.com/dpsd19049
### Advanced Interaction Tecnologies & Applications Github Personal Repository: https://github.com/dpsd19049/Advanced-Interaction-Tecnologies-Applications-Individual-Assignment

# Introduction

# Summary


# 1st Deliverable
1. Video Capture:
   Μελέτησα το tutorial από το link που μας δώθηκε και στη συνέχεια έτρεξα το Example 16-1 από το Learning Processing, 2nd Edition. Αντέγραψα τον κώδικα και τον έβαλα στο github.
   
2.Record video: Μελέτησα το example 16-4 και 16-5 από το βιβλίο Learning Processing, 2nd Edition. Στη συνέχεια δημιούργησα έναν φάκελο data και πέρασα το βίντεο μου. Μετά αντέγραψα τον κώδικα από το Example 16-4 και πήρα το κομμάτι του κώδικα για την ταχύτητα του βίντεο από [εδώ](https://github.com/processing/processing-video/blob/master/examples/Movie/Speed/Speed.pde)

3.QR Code:
Μελέτησα το Processing QrCode Library που μας δώθηκε και πήρα το μέρος του κώδικα που είχε. Στη συνέχεια μεταφέρθηκα στο πρόγραμμα Processing και κατέβασα τη βιβλιοθήκη που υπήρχε διαθέσιμη για το QR. Μετά δημιούργησα το QRcode μου [εδώ](https://www.qrcode-monkey.com),δημιούργησα έναν φάκελο data και το πρόσθεσα μέσα σαν png αρχείο. Τέλος δημιούργησα πρόγραμμα με βάση το παράδειγμα 15-1 του βιβλίου Learning Processing, 2nd Edition και για να ανοίγει κατευθείαν το url βοηθήθηκα από [εδώ](https://processing.org/examples/embeddedlinks.html)

4.QR Code-Camera Read:
Έτρεξα το έτοιμο παράδειγμα για το QR από την βιβλιοθήκη που κατέβασα προηγουμένως.Έπειτα δημιούργησα πάλι έναν φάκελο data και έβαλα το QR code που έφτιαξα πριν.Όπως και στην προηγούμενη άσκηση για να ανοίγει κατευθείαν το url βοηθήθηκα από [εδώ](https://processing.org/examples/embeddedlinks.html)

5.Augmented Reality:
Άνοιξα το Processing, πήγα στις βιβλιοθήκες και κατέβασα την NyARToolkit. Στη συνέχεια δημιούργησα έναν φάκελο data όπου έβαλα μια φωτογραφία μου. Τέλος άνοιξα το παράδειγμα simpleLite και το επεξεργάστηκα βάσει αυτών που γνωρίζω από προηγούμενα παραδείγματα, ώστε να βγει το τελικό αποτέλεσμα.

# 2nd Deliverable
1.Background Removal:
Αρχικά μελέτησα το Example 16-12 από το βιβλίο Learning Processing, 2nd Edition. Έτρεξα το example στο πρόγραμμα Processing από τις ήδη υπάρχουσες libraries, πρόσθεσα στον κώδικα την εικόνα και την εντολή background removal. Και τέλος άλλαξα στην else το color σε backgroundReplace.pixels. Επίσης δημιούργησα φάκελο στο github με όνομα data ώστε να προσθέσω την εικόνα.

2.Motion Detection:
Έτρεξα τα examples 16-11 και 16-13 ώστε να υλοποιήσω την exercise 16-7. Ύστερα έτρεξα στην Processing την exercise 16-7 από τα examples και έκανα τις απαραίτητες αλλαγές(αλλαγή στο avg και στο χρώμα).

3.Background Substraction:
Αρχικά κατέβασα την OpenCV for Processing. Μετά έτρεξα το παράδειγμα Background Substraction και μελέτησα το example 16-1 του Learning Processing, 2nd Edition ώστε να χρησιμοποιήσω το capture για να ανοίξει η κάμερα. Τέλος άλλαξα τα χρώματα.
Πλεονεκτήματα OpenCV: Έυκολη εγκατάσταση, αναγνώριση κίνησης. Μειονεκτήματα: Εγκατάσταση OpenCV.

4. Object Tracking:
Αρχικά έτρεξα το Example 16-11, 9-8 και την Exercise 16-5 από το Learning Processing, 2nd Edition για να καταλάβω λίγο πολύ τι πρέπει να κάνω. Αντέγραψα τον κώδικα από το παράδειγμα 16-5 και αντικατέστησα τον κύκλο από το color tracking (16-11) με το φίδι. Πλεονεκτήματα: Γρήγορος εντοπισμός αντικειμένου, Δεν χρειάζεται ποντίκι. 
Μειονεκτήματα: Η χρήση ποντικιού παρέχει περισσότερη ακρίβεια. 

# 3rd Deliverable 
1. reacTIVation-Installation:

1. Έκανα εγκατάσταση της εφαρμογής reacTIVation vision engine.
2. Έκανα export files και τοποθέτησα τον φάκελο στο libraries της Processing.
3. Έκανα εγκατάσταση την εφαρμογή TUIO Simulator.
4. Εγκατέστησα το Java Runtime Environment και με τη βοήθεια ενός ισπανικού βίντεο στο Youtube κατάλαβα πως έπρεπε να τρέξω το παράδειγμα TUIO Demo με τη χρήση του Simulator.

2. Image Processing Application:
Αρχικά μελέτησα τον κώδικα του TUIO Demo για να δω ποιες αλλαγές πρέπει να κάνω. Στη συνέχεια εκτύπωσα τα fidusials και πήρα το φίλτρο όπου η εικόνα γίνεται σκοτεινότερη ανάλογα με το πόσο θέλει ο χρήστης από την επίσημη ιστοσελίδα της Processing.


# Bonus 
Σε συνεργασία: 

First and Last Name: Eleni Vavouraki

University Registration Number: dpsd19009

GitHub Personal Profile: https://github.com/Ebabouraki

Advanced Interaction Tecnologies & Applications Github Personal Repository: https://ebabouraki.github.io/Advanced-Interaction-Tecnologies-Applications-Individual-Assignment


 - Αρχικά για την εγκατάσταση της κάμερας, ακολουθήσαμε τις οδηγίες από [εδώ](http://articlesbyaphysicist.com/simpleopenni_windows.html) και τα βήματα 1-11 του παραδοτέου Bonus στο Github . Επιπλέον, αφού άναψε το πράσινο λαμπάκι της κάμέρας δοκιμάσαμε κάποια έτοιμα παραδείγματα για να σιγουρευτούμε ότι εγκαταστήθηκε σωστά η κάμερα.Στη συνέχεια, κατεβάσαμε την βιβλιοθήκη SimpleOpenNI.
 
 
Bonus 1 deliverable 1:

Αρχικά άνοιξαμε την εφαρμογή **Processing** και κάναμε αντιγραφή σε ένα καινουριο sketch τον κώδικα του παραδείγματος **Project 5: Tracking the Nearest Object** από το 2ο κεφάλαιο του βιβλίου **Making Things See** έτσι ωστε να αναγνωρίζει από την κάμερα πιο είναι το πιο κοντινό σημείο. Επίσης,  αντικαταστήσαμε τον κώδικα για τον κύκλο που ακολουθούσε την κίνηση του κοντινότερου σημείου με τον κώδικα για το φιδάκι με τη βοήθεια από τον κώδικα του παραδείγματος **9-8** του βιβλίου **learning processing 2** A snake following the mouse.Τέλος, αλλάξαμε τις τιμές στην εντολή fill έτσι ώστε οι κύκλοι που δημιουργούν το φίδι να ξεκινούν από μπλέ και να πηγαίνουν προς το πράσινο. Πιο συγκεκριμένα έγινε ως εξής: fill(0, 255-i*5,0+i*5);

https://user-images.githubusercontent.com/100956280/212358352-d474eaee-5cf2-4988-abca-6b7d1fd4d7b8.mp4







Bonus 1 deliverable 2:

Αρχικά άνοιξαμε την εφαρμογή **Processing** και κάναμε αντιγραφή σε ένα καινουριο sketch τον κώδικα του παραδείγματος **Remove_Background_RGB**. Φτιάξαμε έναν φάκελο **data** μέσα στον φάκελο που είναι αποθηκευμένος ο κώδικας και βάλαμε το βίντεο. Στη συνέχεια για την προσθήκη του βίντεο ξανά μελέτησαμε το κώδικα του παραδείγματος **16-4** από το βιβλίο **Learning Processing, 2nd Edition** και με βάση αυτο τροποποίησαμε το παράδειγμα  **Remove_Background_RGB**, το άλλαξαμε και βάλαμε στον κώδικα το όνομα του video μας. Πήγαμε στο video και κοίταξαμε στα properties, στις λεπτομέρειες, τις διαστάσεις (πλάτος ύψος) του. Βάλαμε τις διαστάσεις στο ` size `ώστε το video να εμφανίζεται ομοιόμορφα από πίσω μας.Για να εμφανίζεται το βίντεο σαν background αντί η μαυρη οθόνη, άλλαξαμε τον κώδικα στην **if(userMap[i]!=0)** και συγκεκριμένα στην **else**, η οποία έγινε  `pixels[i] = vidPixels;`. Για να παίζει το βίντεο σε επανάληψη προσθεσαμε την εξης εντολή  ` movie.loop();`. Ο κώδικας αποθηκεύει αρχικά τα pixel του βίντεο και της κάμερας. Από τα pixels τις κάμερας εμφανίζονται αυτά που αντιστοιχούν στον χρήστη και όλα τα υπόλοιπα αντικαθίστανται με τα pixels του βίντεο.


Τι διαφορά έχει η χρήση της έτοιμης βιβλιοθήκης για την αφαίρεση του υποβάθρου σε σχέση με τον τρόπο που αφαιρέσατε το υπόβαθρο στο 2ο παραδοτέο;


Η χρήση της έτοιμης βιβλιοθήκης και της κάμερας Kinect μπορεί να κάνει πολύ πιο αποτελεσματικά το backround removal καθώς αναγνωρίζει πολύ εύκολα τα σωματα των ανθρώπων λόγω της τεχνολογίας της σε αντίθεση με την απλή κάμερα του λάπτοπ όπως καναμε στο 2ο παραδοτέο.


https://user-images.githubusercontent.com/100956280/212208153-4beb3193-bb85-4b7a-bd23-804d059651ca.mp4

Bonus 1 deliverable 3:

Χρησιμοποιήσαμε τον κώδικα από [εδώ](http://articlesbyaphysicist.com/simpleopenni_windows_2.html) και τον κάναμε αντιγραφή σε ένα καινουριο sketch. Στη συνέχεια, αντικαταστήσαμε τον κώδικα του κύκλου που ακολουθεί το αριστερό χέρι με τον κώδικα του φιδιού όπως στο 1ο ερώτημα του Bonus 1. Aλλάξαμε τις τιμές στην εντολή fill έτσι ώστε οι κύκλοι που δημιουργούν το φίδι να ξεκινούν από μπλέ και να πηγαίνουν προς το πράσινο. Πιο συγκεκριμένα έγινε ως εξής: fill(0, 255-i*5,0+i*5); και αλλάξαμε τον κώδικα ώστε η κάμερα να κάνει track το δεξί χέρι αντί το αριστερό.
 PVector rightHand = new PVector();
 PVector convertedRightHand = new PVector();



# Conclusions
Η διαδικασία υλοποίησης των παραπάνω παραδοτέων πραγματοποιήθηκε έπειτα από πολύωρη προσπάθεια και μετά από πολλές δοκιμές και αλλαγες στον κώδικα.

# Sources
